---
title: "Toxic Comment Classifier"
output: html_notebook
---

### Libraries

```{r, message = FALSE, warning = FALSE}
library(readr)
library(stringi)
library(quanteda)
library(caret)
library(glmnet)
library(doParallel)
registerDoParallel(2)
```

### Importing and Cleaning

```{r, warning = FALSE, message = FALSE}
train = read_csv("~/Programming/Rstudio/Kaggles/ToxicComment/train.csv")
train = train[1:100000,]
sample = sample(nrow(train), nrow(train)/2)
test = train[-sample,]
train = train[sample,]
#test = read_csv("~/Programming/Rstudio/Kaggles/ToxicComment/test.csv")
#swear <- read_csv("~/Programming/Rstudio/Kaggles/ToxicComment/swear.csv", col_names = "word")

train$id2 = rep(1:nrow(train))
test$id2 = rep(1:nrow(test))

traintest = rbind(train[,1:2], test[1:2])
gc()
```

### Variable Creation

```{r}
## quanteda
traincorpus = corpus(train$comment_text)
docvars(traincorpus, "id") = train$id2
testcorpus = corpus(test$comment_text)
docvars(testcorpus, "id") = test$id


#Make dfms and explore
traindfm = dfm(traincorpus, remove = stopwords("english"), stem = FALSE, remove_punct = TRUE)
traindfmtrim = dfm_trim(traindfm, min_count = 2000, max_count = 20000)
testdfm = dfm(testcorpus, remove = stopwords("english"), stem = TRUE, remove_punct = TRUE)

swearDict = dictionary(list(swear = swear$word))
trainsweardfm = dfm_lookup(traindfm, swearDict)
docvars(traindfm, "nswear") = matrix(trainsweardfm)[1:nrow(train),]
testsweardfm = dfm_lookup(testdfm, swearDict)
docvars(testdfm, "nswear") = matrix(trainsweardfm)[1:nrow(test),]

toxicdfm = dfm_subset(traindfm, toxic == 1)
toxicfeatures = topfeatures(toxicdfm, 10)
toxicwords = names(toxicfeatures)

severe_toxicdfm = dfm_subset(traindfm, severe_toxic == 1)
severe_toxicfeatures = topfeatures(severe_toxicdfm, 10)
severe_toxicwords = names(severe_toxicfeatures)

obscenedfm = dfm_subset(traindfm, obscene == 1)
obscenefeatures = topfeatures(obscenedfm, 10)
obscenewords = names(obscenefeatures)

threatdfm = dfm_subset(traindfm, threat == 1)
threatfeatures = topfeatures(threatdfm, 10)
threatwords = names(threatfeatures)

insultdfm = dfm_subset(traindfm, insult == 1)
insultfeatures = topfeatures(insultdfm, 10)
insultwords = names(insultfeatures)

identity_hatedfm = dfm_subset(traindfm, identity_hate == 1)
identity_hatefeatures = topfeatures(identity_hatedfm, 10)
identity_hatewords = names(identity_hatefeatures)

identifyingDict = dictionary(list(toxic = toxicwords,
                                  severe_toxic = severe_toxicwords,
                                  obscene = obscenewords,
                                  threat = threatwords,
                                  insult = insultwords,
                                  identity_hate = identity_hatewords))

trainidentifyingdfm = dfm_lookup(traindfm, identifyingDict)
docvars(traindfm, "ntoxic") = matrix(trainidentifyingdfm)[1:nrow(train),]
docvars(traindfm, "nsevere_toxic") = matrix(trainidentifyingdfm)[(nrow(train)+1):(2*nrow(train)),]
docvars(traindfm, "nobscene") = matrix(trainidentifyingdfm)[(2*nrow(train)+1):(3*nrow(train)),]
docvars(traindfm, "nthreat") = matrix(trainidentifyingdfm)[(3*nrow(train)+1):(4*nrow(train)),]
docvars(traindfm, "ninsult") = matrix(trainidentifyingdfm)[(4*nrow(train)+1):(5*nrow(train)),]
docvars(traindfm, "nidentity_hate") = matrix(trainidentifyingdfm)[(5*nrow(train)+1):(6*nrow(train)),]
train = cbind(train, traindfm@docvars[8:15])

testidentifyingdfm = dfm_lookup(testdfm, identifyingDict)
docvars(testdfm, "ntoxic") = matrix(testidentifyingdfm)[1:nrow(test),]
docvars(testdfm, "nsevere_toxic") = matrix(testidentifyingdfm)[(nrow(test)+1):(2*nrow(test)),]
docvars(testdfm, "nobscene") = matrix(testidentifyingdfm)[(2*nrow(test)+1):(3*nrow(test)),]
docvars(testdfm, "nthreat") = matrix(testidentifyingdfm)[(3*nrow(test)+1):(4*nrow(test)),]
docvars(testdfm, "ninsult") = matrix(testidentifyingdfm)[(4*nrow(test)+1):(5*nrow(test)),]
docvars(testdfm, "nidentity_hate") = matrix(testidentifyingdfm)[(5*nrow(test)+1):(6*nrow(test)),]
test = cbind(test, testdfm@docvars[c(1,3:9)])
```




### Model Building

```{r}
toxicglog = glm(toxic ~ ntokens + ntoxic + nsevere_toxic + nobscene + 
                  nthreat + ninsult + nidentity_hate + nswear,
                data = train, family = "binomial")
toxicpreds = predict(toxicglog, newdata = test, type = "response")

severe_toxicglog = glm(severe_toxic ~ ntokens + ntoxic + nsevere_toxic + nobscene + 
                  nthreat + ninsult + nidentity_hate + nswear,
                data = train, family = "binomial")
severe_toxicpreds = predict(severe_toxicglog, newdata = test, type = "response")

obsceneglog = glm(obscene ~ ntokens + ntoxic + nsevere_toxic + nobscene + 
                  nthreat + ninsult + nidentity_hate + nswear,
                data = train, family = "binomial")
obscenepreds = predict(obsceneglog, newdata = test, type = "response")

threatglog = glm(threat ~ ntokens + ntoxic + nsevere_toxic + nobscene + 
                  nthreat + ninsult + nidentity_hate + nswear,
                data = train, family = "binomial")
threatpreds = predict(threatglog, newdata = test, type = "response")

insultglog = glm(insult ~ ntokens + ntoxic + nsevere_toxic + nobscene + 
                  nthreat + ninsult + nidentity_hate + nswear,
                data = train, family = "binomial")
insultpreds = predict(insultglog, newdata = test, type = "response")

identity_hateglog = glm(identity_hate ~ ntokens + ntoxic + nsevere_toxic + nobscene + 
                  nthreat + ninsult + nidentity_hate + nswear,
                data = train, family = "binomial")
identity_hatepreds = predict(identity_hateglog, newdata = test, type = "response")

submission = cbind(test$id, toxicpreds, severe_toxicpreds,
                   obscenepreds, threatpreds, insultpreds, identity_hatepreds)
colnames(submission) <- c("id", "toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate")
write_csv(as.data.frame(submission), "submission.csv")
```


```{r}
train$comment_text = unlist(train$comment_text)
cvglm <- cv.glmnet(as.tibble(train[10:17]), train$identity_hate, alpha = 0, family = "binomial", type.measure = "auc",
                     parallel = T, nfolds = 4, standardize = T,  nlambda = 50)
cvglmpreds = predict(cvglm, as.matrix(test[4:11]))
cvglmpreds = ifelse(cvglmpreds <= 0.5, 0, 1)
confusionMatrix(table(cvglmpreds, test$toxic))




```

