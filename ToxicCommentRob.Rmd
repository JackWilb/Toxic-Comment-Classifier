---
title: "toxic_counts"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(knitr)
library(stringi)
library(stringr)
library(readr)
library(quanteda)
library(dplyr)
library(glmnet)
library(caret)
#library(doParallel)
#library(ngram)
library(readr)
library(mosaic)
library(broom)
library(cleanNLP)
library(tm)
library(tidytext)
library(sentimentr)
library(data.table)
library(magrittr)
library(randomForest)
library(class)
library(e1071)
library(nnet)
library(neuralnet)
library(randomForest)
library(ranger)
library(ISLR)
library(caret)
library(boot)
library(syuzhet)
```


```{r}
toxic.train<-fread("train.csv", sep=',')
set.seed(1)
#sample = sample(nrow(toxic.train), nrow(toxic.train)*.99)
toxic_test = toxic.train[1:20000]
toxic_train = toxic.train[20001:40000]
#traintest = rbind(toxic_train[,1:2], toxic_test[1:2])

stopWords = c(stop_words$word, "of", "or", "on")
stopWords=stopWords[!(stopWords %in% c("new","used","small","large","thanks","greetings","works"))]


swears<-fread("swears.csv", sep = ",")
hatewords<-fread("hatebase_dict.csv",sep=",")
#swears2 <-fread("swearlistcscmu.csv",sep=",")

swears<-unique( swears[ , 1:2 ] )
swears$x <- gsub(",","",swears$x)
#swears<-rbind(swears,swears2)
swears<-unique(swears[,1:2])
mykey.swear<-update_key(swears)


hatewords<-unique(hatewords[,1:2])
hatewords$words<-gsub(",","",hatewords$words)
hatewords$words<-gsub("'"," ",hatewords$words)
hatewords$words<-tolower(hatewords$words)
hatewords
colnames(hatewords)[1] <- "x"
colnames(hatewords)[2]<-"y"
key.hatewords <- update_key(hatewords)


####clean comment_text


cmmnt = toxic_train$comment_text
cmmnt = unlist(cmmnt)[!(unlist(cmmnt) %in% stopWords)]
cmmnt = stri_replace_all_charclass(cmmnt, "[^[:alnum:]]", " ")
id = rep(1:nrow(toxic_train))
cmmnt_df = data.frame(id = id, comments = cmmnt)
cmmnt_df$comments = as.character(cmmnt_df$comments)
cmmnt


cmmnt.t = toxic_test$comment_text
cmmnt.t = unlist(cmmnt.t)[!(unlist(cmmnt.t) %in% stopWords)]
cmmnt.t = stri_replace_all_charclass(cmmnt.t, "[^[:alnum:]]", " ")
id = rep(1:nrow(toxic_test))
cmmnt_df.t = data.frame(id = id, comments = cmmnt.t)
cmmnt_df.t$comments = as.character(cmmnt_df.t$comments)


##create traintest/.t dfm
traintest = mutate(toxic_train,
       length = stri_length(comment_text),
       ncap = stri_count_charclass(comment_text, "[A-Z]"),
       nnum = stri_count_charclass(comment_text, "[0-9]"),
       ncap_len = ncap / length,
       nexcl = stri_count_fixed(comment_text, "!"),
       nquest = stri_count_fixed(comment_text, "?"),
       npunct = stri_count_charclass(comment_text, "[[:punct:]]"),
       npunct_len = npunct / length,
       nsent = stri_count_boundaries(comment_text, "sentence"),
       nsymb = stri_count_regex(comment_text, "&|@|#|\\$|%|\\*|\\^"),
       nsmile = stri_count_regex(comment_text, "((?::|;|=)(?:-)?(?:\\)|D|P))"),
       nwords = stri_count_words(comment_text),
       hate=stri_count_fixed(comment_text,c("nigger","fag")),
       nhate=stri_count_regex(comment_text, "[[hatewords$x]]")
       #ntokens=length(!duplicated(comment_text)),
       #ntokens_nwords = ntokens / nwords
       )


traintest.t = mutate(toxic_test,
       length = stri_length(comment_text),
       ncap = stri_count_charclass(comment_text, "[A-Z]"),
       nnum = stri_count_charclass(comment_text, "[0-9]"),
       ncap_len = ncap / length,
       nexcl = stri_count_fixed(comment_text, "!"),
       nquest = stri_count_fixed(comment_text, "?"),
       npunct = stri_count_charclass(comment_text, "[[:punct:]]"),
       npunct_len = npunct / length,
       nsent = stri_count_boundaries(comment_text, "sentence"),
       nsymb = stri_count_regex(comment_text, "&|@|#|\\$|%|\\*|\\^"),
       nsmile = stri_count_regex(comment_text, "((?::|;|=)(?:-)?(?:\\)|D|P))"),
       nwords = stri_count_words(comment_text),
       hate=stri_count_fixed(comment_text,c("niggers","fag")),
       nhate=stri_count_regex(comment_text, "[[hatewords$x]]")
       #ntokens=length(!duplicated(comment_text)),
       #ntokens_nwords = ntokens / nwords
       )

toxic_test<-cbind(toxic_test,traintest.t[,9:22])
toxic_train<-cbind(toxic_train,traintest[,9:22])
```
```{r}
###sentiment values based on swears  added on onto DFM
swear.sent.train<-sentiment_by(cmmnt_df$comments,list(id), polarity_dt=mykey.swear)
swear.sent.test<-sentiment_by(cmmnt_df.t$comments,list(id),polarity_dt=mykey.swear)

swear.sent.test
colnames(swear.sent.test)[4] <- "swear_sent"
colnames(swear.sent.train)[4]<-"swear_sent"

hate.sent.train<-sentiment_by(cmmnt_df$comments,list(id), polarity_dt=key.hatewords)
hate.sent.test<-sentiment_by(cmmnt_df.t$comments,list(id),polarity_dt=key.hatewords)

colnames(hate.sent.test)[4] <- "hate_sent"
colnames(hate.sent.train)[4]<-"hate_sent"

toxic_train<-cbind(toxic_train,swear.sent.train[,4])
toxic_test<-cbind(toxic_test,swear.sent.test[,4])
toxic_train<-cbind(toxic_train,hate.sent.train[,4])
toxic_test<-cbind(toxic_test,hate.sent.test[,4])
###positive sent- afinn
pos.sent<-sentiment_by(cmmnt_df$comments, list(id), lexicon="afinn")
pos.sent.t<-sentiment_by(cmmnt_df$comments, list(id), lexicon="afinn")

colnames(pos.sent)[4] <- "afinn"
colnames(pos.sent.t)[4]<-"afinn"

toxic_train<-cbind(toxic_train,pos.sent[,4])
toxic_test<-cbind(toxic_test,pos.sent.t[,4])

## create non toxic value
#train
toxic_train$non_toxic<-ifelse(toxic_train$toxic=="0","1","0")
toxic_train$non_severe_toxic<-ifelse(toxic_train$severe_toxic=="0","1","0") 
toxic_train$non_obscene<-ifelse(toxic_train$obscene=="0","1","0") 
toxic_train$non_threat<-ifelse(toxic_train$threat=="0","1","0") 
toxic_train$non_insult<-ifelse(toxic_train$insult=="0","1","0") 
toxic_train$non_identity_hate<-ifelse(toxic_train$identity_hate=="0","1","0") 

#test
toxic_test$non_toxic<-ifelse(toxic_test$toxic=="0","1","0")
toxic_test$non_severe_toxic<-ifelse(toxic_test$severe_toxic=="0","1","0") 
toxic_test$non_obscene<-ifelse(toxic_test$obscene=="0","1","0") 
toxic_test$non_threat<-ifelse(toxic_test$threat=="0","1","0") 
toxic_test$non_insult<-ifelse(toxic_test$insult=="0","1","0") 
toxic_test$non_identity_hate<-ifelse(toxic_test$identity_hate=="0","1","0") 
```
```{r}
####GLM models
#Non-toxic
non.toxic.lr<-glm(as.numeric(non_toxic)~length+ncap+nnum+ncap_len+nexcl+nquest+npunct+npunct_len+nsent+nsymb+nsmile+nwords+swear_sent+hate_sent+afinn,data=toxic_train,family=binomial)
non.toxic.prob<-predict(non.toxic.lr,newdata=toxic_test, type="response")
non.toxic.pred<-ifelse(non.toxic.prob>.9,"1","0")
confusionMatrix(non.toxic.pred,toxic_test$non_toxic, positive="1")
#non-severetoxic
non.severe.toxic.lr<-glm(as.numeric(non_severe_toxic)~length+ncap+nnum+ncap_len+nexcl+nquest+npunct+npunct_len+nsent+nsymb+nsmile+nwords+swear_sent+hate_sent+afinn,data=toxic_train,family=binomial)
non.severe.toxic.prob<-predict(non.toxic.lr,newdata=toxic_test, type="response")
non.severe.toxic.pred<-ifelse(non.toxic.prob>.5,"1","0")
confusionMatrix(non.severe.toxic.pred,toxic_test$non_severe_toxic, positive="1")

#non obscene
non.obscene.lr<-glm(as.numeric(non_obscene)~length+ncap+nnum+ncap_len+nexcl+nquest+npunct+npunct_len+nsent+nsymb+nsmile+nwords+swear_sent+hate+nhate+afinn,data=toxic_train,family=binomial)
non.obscene.prob<-predict(non.obscene.lr,newdata=toxic_test, type="response")
non.obscene.pred<-ifelse(non.toxic.prob>.9999999,"1","0")
confusionMatrix(non.obscene.pred,toxic_test$non_obscene, positive="1")

### non insult
non.insult.lr<-glm(as.numeric(non_insult)~length+ncap+nnum+ncap_len+nexcl+nquest+npunct+npunct_len+nsent+nsymb+nsmile+nwords+swear_sent+hate_sent+afinn,data=toxic_train,family=binomial)
non.insult.prob<-predict(non.insult.lr,newdata=toxic_test, type="response")
non.insult.pred<-ifelse(non.insult.prob>.999,"1","0")
confusionMatrix(non.insult.pred,toxic_test$non_insult, positive="1")


##non identity hate
non.hate.lr<-glm(as.numeric(non_identity_hate)~length+ncap+nnum+ncap_len+nexcl+nquest+npunct+npunct_len+nsent+nsymb+nsmile+nwords+swear_sent+hate_sent+afinn,data=toxic_train,family=binomial)
non.hate.prob<-predict(non.hate.lr,newdata=toxic_test, type="response")
non.hate.pred<-ifelse(non.hate.prob>.9,"1","0")
confusionMatrix(non.hate.pred,toxic_test$non_identity_hate, positive="1")


##toxic.---goood 9346. 9363+hate
toxic.lr<-glm(toxic~swear_sent+hate_sent+length+ncap+ncap_len+nexcl+nquest+npunct_len+nsent+nsymb+nwords+nhate, data=toxic_train, family= binomial)

summary(toxic.lr)

toxic_prob<-predict(toxic.lr, newdata=toxic_test,type="response")

toxic_pred<-ifelse(toxic_prob>.9,"1","0")

confusionMatrix(toxic_pred, toxic_test$toxic, positive = "1")

###severe toxic --- no good

s.toxic.lr<-glm(severe_toxic~swear_sent+ncap+ncap_len+nexcl+nquest+npunct_len+nsent+nsymb+nwords+nhate, data=toxic_train, family= binomial)

summary(s.toxic.lr)

s.toxic_prob<-predict(s.toxic.lr, newdata=toxic_test,type="response")

s.toxic_pred<-ifelse(s.toxic_prob>.7,"1","0")

confusionMatrix(s.toxic_pred, toxic_test$severe_toxic, positive = "1")

##obscene--- goood,.9628swear sent  9643 +hate_sent
obscene.lr <-glm(obscene~swear_sent+hate_sent+ncap+ncap_len+nquest+nsent+nsymb+nwords+nhate, data=toxic_train, family= binomial)

summary(obscene.lr)

swear_prob<-predict(obscene.lr, newdata=toxic_test,type="response")

obscene_pred<-ifelse(swear_prob>.3,"1","0")

confusionMatrix(obscene_pred, toxic_test$obscene, positive = "1")

###insult--good
insult.lr<-glm(insult~swear_sent+hate_sent+ncap_len+nquest+npunct_len+nsymb+nwords+nhate, data=toxic_train, family= binomial)

summary(insult.lr)

insult_prob<-predict(insult.lr, newdata=toxic_test,type="response")

insult_pred<-ifelse(insult_prob>.2,"1","0")

confusionMatrix(insult_pred, toxic_test$insult, positive = "1")

###threat---no good

threat.lr<-glm(threat~swear_sent+ncap_len+npunct_len+nsent+nsymb+nwords+nhate, data=toxic_train, family=binomial)
threat_prob<-predict(threat.lr, newdata=toxic_test,type="response")

summary(threat.lr)

threat_pred<-ifelse(threat_prob>.04,"1","0")

confusionMatrix(threat_pred, toxic_test$threat, positive = "1")

##hate

hate.lr<-glm(identity_hate~ncap_len+npunct_len+nsent+nwords+nhate, data=toxic_train, family=binomial)

summary(hate.lr)

hate_prob<-predict(hate.lr, newdata=toxic_test,type="response")

hate_pred<-ifelse(hate_prob>.4,"1","0")

confusionMatrix(hate_pred, toxic_test$identity_hate, positive = "1")

```

###lasso
```{r}
##make model matrix
#X_train<-model.matrix(obscene~word_count+swear_sent, data=toxic_train)
#X_train<-X_train[,-1]
#y_train<-toxic_train$obscene
#X_test<-model.matrix(obscene~word_count+swear_sent, data=toxic_test)
#X_test<-X_test[,-1]
#y_test<-toxic_test$obscene
##lasso
#lasso_mod<-glmnet(X_train,y_train,alpha=1)
#lasso<-cv.glmnet(X_train,y_train,alpha=1)
#best_lasso<-lasso$lambda.min
#lasso_pred<-predict(lasso_mod,s=best_lasso,newx=X_test)
#best_lasso
#mean((lasso_pred-y_test)^2)
#autoplot(lasso)

#lasso_final<-glmnet(X_train,y_train,alpha=1)
#autoplot(lasso_final,xvar="lambda")
#lasso_coef<-predict(lasso_final,type="coefficients",s=best_lasso)
#lasso_coef


##training model matrix
toxic.ridge<-model.matrix(toxic~swear_sent+hate_sent+length+ncap+ncap_len+nexcl+nquest+npunct_len+nsent+nsymb+nwords+hate+nhate, data=toxic_train)
toxic.ridge<-toxic.ridge[,-1]
toxic.y.train<-toxic_train$toxic
## test model matrix
toxic.ridge.t<-model.matrix(toxic~swear_sent+hate_sent+length+ncap+ncap_len+nexcl+nquest+npunct_len+nsent+nsymb+nwords+hate+nhate, data=toxic_test)
toxic.ridge.t<-toxic.ridge.t[,-1]
toxic.y.test<-toxic_test$toxic
##lasso model
cv.toxic.lasso<-cv.glmnet(toxic.ridge,toxic.y.train, alpha=1)
#autoplot(cv.crim.lasso)
lasso.pred.toxic<- predict(cv.toxic.lasso, s=cv.toxic.lasso$lambda.min, newx=toxic.ridge.t)

toxic_preds<-ifelse(lasso.pred.toxic>.4,"1","0")
confusionMatrix(toxic_preds, toxic.y.test, positive="1")


```