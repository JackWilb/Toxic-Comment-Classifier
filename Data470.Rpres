Natural Language Processing In R: A Wikipedia Case Study
========================================================
author: Jack Wilburn and Rob Squire
font-family: Georgia
date: 20th April 2018
autosize: true

```{r setup, include=FALSE}
opts_chunk$set(cache=TRUE)
```

Motivation
========================================================

* Text Analysis
* Develop Techniques
  - Data Aggregation/Cleaning
  - Modeling
  - Reporting

Objectives
========================================================

* Natural Language Processing (NLP)
  - Body Of Text
  - Useful Variables
* Predictive Modeling
  - Explantory Variables
  - 6 Response Variables
  - Inference
  
Methods 
========================================================

* Explore Raw Data

* Clean Data

* Create Variables

* Split data
  - Training/Test
  
Methods 
========================================================  

* Implement models 
  - Cross Validated Logistic Regression

* Assess Accuracy
  - Confusion Matrix

Libraries
========================================================

```{r, include = FALSE}
library(readr)
library(stringi)
library(quanteda)
library(dplyr)
library(caret)
library(glmnet)
library(doParallel)
registerDoParallel(4)
library(tidytext)
library(data.table)
library(sentimentr)
library(tm)
library(lexicon)
```

* readr
* stringi
* quanteda
* dplyr
* caret
* tm

***

* glmnet
* doParallel
* tidytext
* data.table
* sentimentr

Exploratory Data Analysis
========================================================

```{r,include=FALSE}
library(tidyverse)
train = read_csv("train.csv")
```

* Structure Of The Data
```{r, echo=FALSE}
head(as.data.frame(train[100,]), 1)
```

Exploratory Data Analysis
========================================================

```{r, include=FALSE}
table(train$toxic)
table(train$obscene)
table(train$threat)
table(train$insult)
table(train$identity_hate)
```

* Toxic: `r (15294/159571)*100` %.

* Severe_toxic: `r (1595/159571)*100 ` %.

* Obscene: `r (8449/159571)*100 ` %.

* Threat: `r (478/159571)*100 ` %.

* Insult: `r (7877/159571)*100 ` %.

* Identity Hate: `r (1405/159571)*100 ` %.

Tidy Text Word Analysis
========================================================

```{r, warning=FALSE, include=FALSE}
traincorpus = corpus(train$comment_text)
docvars(traincorpus, "id") = 1:nrow(train)
docvars(traincorpus, "toxic") = train$toxic
docvars(traincorpus, "severe_toxic") = train$severe_toxic
docvars(traincorpus, "obscene") = train$obscene
docvars(traincorpus, "threat") = train$threat
docvars(traincorpus, "insult") = train$insult
docvars(traincorpus, "identity_hate") = train$identity_hate
docvars(traincorpus, "ntokens") = ntoken(traincorpus, remove_punct = TRUE)

traindfm2 = dfm(traincorpus, remove = stopwords("english"), stem = TRUE, remove_punct = TRUE)
toxicdfm2 = dfm_subset(traindfm2, toxic == 1, remove = stopwords("english"))
toxicfeatures2 = topfeatures(toxicdfm2, 10)
toxicwords2 = names(toxicfeatures2)

severe_toxicdfm2 = dfm_subset(traindfm2, severe_toxic == 1,remove = stopwords("english"))
severe_toxicfeatures2 = topfeatures(severe_toxicdfm2, 10)
severe_toxicwords2 = names(severe_toxicfeatures2)

obscenedfm2 = dfm_subset(traindfm2, obscene == 1,remove = stopwords("english"))
obscenefeatures2 = topfeatures(obscenedfm2, 10)
obscenewords2 = names(obscenefeatures2)

threatdfm2 = dfm_subset(traindfm2, threat == 1,remove = stopwords("english"))
threatfeatures2 = topfeatures(threatdfm2, 10)
threatwords2 = names(threatfeatures2)

insultdfm2 = dfm_subset(traindfm2, insult == 1,remove = stopwords("english"))
insultfeatures2 = topfeatures(insultdfm2, 10)
insultwords2 = names(insultfeatures2)

identity_hatedfm2 = dfm_subset(traindfm2, identity_hate == 1,remove = stopwords("english"))
identity_hatefeatures2 = topfeatures(identity_hatedfm2, 10)
identity_hatewords2 = names(identity_hatefeatures2)

a = data.frame(term = c("f**k","ni**er","a*s","sex","hate","go","c*nt","like","suck","moron"), freq = unname(toxicfeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    labs(x = '', y = 'Frequency', title = 'Most common Toxic Words') + 
    coord_flip()

b = data.frame(term = c("f**k","a*s","suck","u","go","bastard","c*nt","athiest","fire","pro.assad.hannibal911you'r"), freq = unname(severe_toxicfeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    labs(x = '', y = 'Frequency', title = 'Most common Severe_toxic Words ') + 
    coord_flip() 

c = data.frame(term = c("f**k","ni**er","a*s","c*nt","suck","go","u","bollock","d*ckhead","like"), freq = unname(obscenefeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    labs(x = '', y = 'Frequency', title = 'Most common Obscene Words') + 
    coord_flip() 

d = data.frame(term = c("a*s","will","supertr0l","die","live","pathet(ic)","forev(er)","fool","respect","f**k"), freq = unname(threatfeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    labs(x = '', y = 'Frequency', title = 'Most common Threat Word') + 
    coord_flip() 

e = data.frame(term = c("f**k","ni**er","a*s","hate","c*nt","go","moron","hi","u","suck"), freq = unname(insultfeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    labs(x = '', y = 'Frequency', title = 'Most common Insult Word') + 
    coord_flip() 


f = data.frame(term = c("ni**er","c*nt","tommy2010","licker","fan-1967","like","romney","mitt","homo","f**k"), freq = unname(identity_hatefeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    labs(x = '', y = 'Frequency', title = 'Most common Identity_hate Word') + 
    coord_flip() 
```

```{r, echo = FALSE, fig.width = 18, fig.height = 10}
gridExtra::grid.arrange(a,b, ncol = 2)
```

Tidy Text Word Analysis
========================================================

```{r, echo = FALSE, fig.width = 18, fig.height = 10}
gridExtra::grid.arrange(c,d, ncol = 2)
```

Tidy Text Word Analysis
========================================================

```{r, echo = FALSE, fig.width = 18, fig.height = 10}
gridExtra::grid.arrange(e,f, ncol = 2)
```


These word frequency visuals gives us an idea of words associated with certain classifications.  We can add counts of these words into our variable creation to make better predictions.



PCA
========================================================

```{r, echo=FALSE, fig.width=8, fig.height=8}
train_num<-select_if(train, is.numeric)
train_num<-na.omit(train_num)
train_pca<- prcomp(train_num, scale=TRUE)
biplot(train_pca, xlabs=rep("",159571))
```

Variables Created
========================================================

* Feature Count 
  -punctuation
  -capital letters
  -smileys
  
* Sentiment analysis
  -Standard Lexicon/ library - AFINN
  - Custom lexicon
    -Swear
    -Hate
    
* Sparse Document Feature Matrix
  -counts of every possible "feature"
    -words, punt, multiple words
    -4000 features.
   


Results
========================================================

```{r, include=FALSE}
train = train[2:159571,]
sample = sample(nrow(train), nrow(train)/2)
test = train[-sample,]
train = train[sample,]
idtrain = 1:nrow(train)
idtest = (nrow(train)+1):(nrow(train) + nrow(test))
traintest = rbind(train[,1:2], test[1:2])
gc()

traintest = rbind(train[,1:2], test[1:2])
traintest = mutate(traintest,
       length = stri_length(comment_text),
       ncap = stri_count_charclass(comment_text, "[A-Z]"),
       nnum = stri_count_charclass(comment_text, "[0-9]"),
       ncap_len = ncap / length,
       nnum_len = nnum / length,
       nexcl = stri_count_fixed(comment_text, "!"),
       nquest = stri_count_fixed(comment_text, "?"),
       npunct = stri_count_charclass(comment_text, "[[:punct:]]"),
       npunct_len = npunct / length,
       nsent = stri_count_boundaries(comment_text, "sentence"),
       nsymb = stri_count_regex(comment_text, "&|@|#|\\$|%|\\*|\\^"),
       nsmile = stri_count_regex(comment_text, "((?::|;|=)(?:-)?(?:\\)|D|P))"),
       nwords = stri_count_words(comment_text)
       )
train = cbind(train, traintest[idtrain,3:ncol(traintest)])
test = cbind(test, traintest[idtest,3:ncol(traintest)])

###swears
swears<-fread("swears.csv", sep = ",")
hatewords<-fread("hatebase_dict1.csv",sep=",")
#swears2 <-fread("swearlistcscmu.csv",sep=",")
#swears3<-fread("googleswear.csv",sep=",")


swears<-unique( swears[ , 1:2 ] )
swears$x <- gsub(",","",swears$x)
#swears<-rbind(swears,swears2)
#swears<-rbind(swears,swears3)
swears<-unique(swears[,1:2])
mykey.swear<-update_key(swears)


hatewords<-unique(hatewords[,1:2])
hatewords$words<-gsub(",","",hatewords$words)
hatewords$words<-gsub("'"," ",hatewords$words)

hatewords$words<-tolower(hatewords$words)
hatewords
colnames(hatewords)[1] <- "x"
colnames(hatewords)[2]<-"y"
hatewords<-unique(hatewords[,1:2])
key.hatewords <- update_key(hatewords)

stopWords = c(stop_words$word, "of", "or", "on")
stopWords=stopWords[!(stopWords %in% c("new","used","small","large","thanks","greetings","works"))]

cmmnt = train$comment_text
cmmnt = unlist(cmmnt)[!(unlist(cmmnt) %in% stopWords)]
cmmnt = stri_replace_all_charclass(cmmnt, "[^[:alnum:]]", " ")
id = rep(1:nrow(train))
cmmnt_df = data.frame(id = id, comments = cmmnt)
cmmnt_df$comments = as.character(cmmnt_df$comments)


cmmnt.t = test$comment_text
cmmnt.t = unlist(cmmnt.t)[!(unlist(cmmnt.t) %in% stopWords)]
cmmnt.t = stri_replace_all_charclass(cmmnt.t, "[^[:alnum:]]", " ")
id = rep(1:nrow(test))
cmmnt_df.t = data.frame(id = id, comments = cmmnt.t)
cmmnt_df.t$comments = as.character(cmmnt_df.t$comments)


swear.sent.train<-sentiment_by(cmmnt_df$comments,list(id), polarity_dt=mykey.swear)
swear.sent.test<-sentiment_by(cmmnt_df.t$comments,list(id),polarity_dt=mykey.swear)

colnames(swear.sent.test)[4] <- "swear_sent"
colnames(swear.sent.train)[4]<-"swear_sent"


#cmmnt_df$comments<-na.omit(cmmnt_df$comments)
#cmmnt_df.t$comments<-na.omit(cmmnt_df.t$comments)

#hate.sent.train<-sentiment_by(cmmnt_df$comments,list(id), polarity_dt=key.hatewords)
#hate.sent.test<-sentiment_by(cmmnt_df.t$comments,list(id),polarity_dt=key.hatewords)

#colnames(hate.sent.test)[4] <- "hate_sent"
#colnames(hate.sent.train)[4]<-"hate_sent"

train<-cbind(train,swear.sent.train[,4])
test<-cbind(test,swear.sent.test[,4])
#train<-cbind(train,hate.sent.train[,4])
#test<-cbind(test,hate.sent.test[,4])
###positive sent- afinn
pos.sent<-sentiment_by(cmmnt_df$comments, list(id), lexicon="afinn")
pos.sent.t<-sentiment_by(cmmnt_df$comments, list(id), lexicon="afinn")

colnames(pos.sent)[4] <- "afinn"
colnames(pos.sent.t)[4]<-"afinn"

train<-cbind(train,pos.sent[,4])
test<-cbind(test,pos.sent.t[,4])


## quanteda
ttcorp = corpus(traintest$comment_text)
ttdfm = dfm(ttcorp, remove = stopwords("english"))
ttdfm = dfm_trim(ttdfm, min_docfreq = 150, max_docfreq = 100000)
ttdfm = dfm_sort(ttdfm)

# sparse matrix
sumttdfm = summary(ttdfm)
sparsettdfm = sparseMatrix(i = sumttdfm$i, j = sumttdfm$j, x = sumttdfm$x)

sparsetrain = Matrix(as.matrix(train[3:23]), sparse = TRUE)
sparsetest = Matrix(as.matrix(test[3:23]), sparse = TRUE)
train = cbind(sparsetrain, sparsettdfm[1:nrow(train),])
test = cbind(sparsetest, sparsettdfm[(nrow(train)+1):(nrow(train) + nrow(test)),])
rm(sparsetrain, sparsetest)

toxicglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,1]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 40,
                     standardize = T,
                     nlambda = 50)
toxicpreds = predict(toxicglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
toxicpreds = ifelse(toxicpreds > 0.0099, 1 ,0)
toxicconf = confusionMatrix(factor(toxicpreds), factor(test[,1]))

severe_toxicglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,2]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
severe_toxicpreds = predict(severe_toxicglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
severe_toxicpreds = ifelse(severe_toxicpreds > 0.016, 1 ,0)
severe_toxicconf = confusionMatrix(factor(severe_toxicpreds), factor(test[,2]))

obsceneglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,3]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
obscenepreds = predict(obsceneglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
obscenepreds = ifelse(obscenepreds > 0.23, 1 ,0)
obsceneconf = confusionMatrix(factor(obscenepreds), factor(test[,3]))

threatglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,4]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
threatpreds = predict(threatglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
threatpreds = ifelse(threatpreds > 0.004, 1 ,0)
threatconf = confusionMatrix(factor(threatpreds), factor(test[,4]))

insultglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,5]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
insultpreds = predict(insultglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
insultpreds = ifelse(insultpreds > 0.255, 1 ,0)
insultconf = confusionMatrix(factor(insultpreds), factor(test[,5]))

identity_hateglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,6]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
identity_hatepreds = predict(identity_hateglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
identity_hatepreds = ifelse(identity_hatepreds > 0.3, 1 ,0)
identity_hateconf = confusionMatrix(factor(identity_hatepreds), factor(test[,6]))
```


Toxic = `r unname((toxicconf$overall[1]-toxicconf$overall[5])/(1-toxicconf$overall[5]))*100`
Severe_Toxic = `r unname((severe_toxicconf$overall[1]-severe_toxicconf$overall[5])/(1-severe_toxicconf$overall[5]))*100`
Obscene = `r unname((obsceneconf$overall[1]-obsceneconf$overall[5])/(1-obsceneconf$overall[5]))*100`
Threat = `r unname((threatconf$overall[1]-threatconf$overall[5])/(1-threatconf$overall[5]))*100`
Insult = `r unname((insultconf$overall[1]-insultconf$overall[5])/(1-insultconf$overall[5]))*100`
Identity_Hate = `r unname((identity_hateconf$overall[1]-identity_hateconf$overall[5])/(1-identity_hateconf$overall[5]))*100`

Discussion
========================================================



Limitations
========================================================

Some categories did not have a large enough sample to predict off of.  The test data contained very zero Identity hate comments.  Threat comments only registered 0.3% of training data.  

Computing power presented a challenge to processing large document feature matrices.

We were able to create some variables that were intuitive and some that were less intuitive.  There exists the possibility that many more predictive variables exists but we were not able to come up with them.


Acknowledgements
========================================================

http://www.bannedwordlist.com/lists/swearWords.txt

https://www.cs.cmu.edu/~biglou/resources/bad-words.txt

https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/lexicons

https://www.tidytextmining.com/tidytext.html

