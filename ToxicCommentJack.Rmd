---
title: "Toxic Comment Classifier"
output: html_notebook
---

### Libraries

```{r, message = FALSE, warning = FALSE}
library(readr)
library(stringi)
library(quanteda)
library(dplyr)
library(caret)
library(glmnet)
library(doParallel)
library(tidytext)
library(data.table)
library(sentimentr)
registerDoParallel(7)
#registerDoParallel(2)
```

### Importing and Cleaning

```{r, warning = FALSE, message = FALSE}
train = read_csv("train.csv")
test = read_csv("test.csv")

testid = test$id

idtrain = 1:nrow(train)
idtest = (nrow(train)+1):(nrow(train) + nrow(test))
gc()
```

### Variable Creation

```{r}
# Rob's work
stopWords = c(stop_words$word, "of", "or", "on")
stopWords=stopWords[!(stopWords %in% c("new","used","small","large","thanks","greetings","works"))]

swears<-fread("swears.csv", sep = ",")
swears$x <- gsub(",","",swears$x)
swears<-unique(swears[,1:2])
mykey.swear<-update_key(swears)

hatewords<-fread("hatebase_dict1.csv",sep=",")
hatewords2<-fread("hate.ngram.csv",sep=",")
hatewords$words<-gsub(",","",hatewords$words)
hatewords$words<-gsub("'"," ",hatewords$words)
hatewords$words<-tolower(hatewords$words)
colnames(hatewords)[1] <- "x"
colnames(hatewords)[2]<-"y"
hatewords<-unique(hatewords[,1:2])
hatewords2<-unique(hatewords2[,1:2])
hatewords<-rbind(hatewords,hatewords2)
key.hatewords <- update_key(hatewords)

rm(hatewords2)

trainsentences = get_sentences(train$comment_text)
testsentenses = get_sentences(test$comment_text)

swear.sent<-sentiment_by(trainsentences,list(train$id), polarity_dt=mykey.swear)
swear.sent.t<-sentiment_by(testsentenses,list(test$id),polarity_dt=mykey.swear)
key.hatewords <- key.hatewords[-c(1014), ]
hate.sent<-sentiment_by(trainsentences,list(train$id), polarity_dt=key.hatewords)
hate.sent.t<-sentiment_by(testsentenses,list(test$id),polarity_dt=key.hatewords)
pos.sent<-sentiment_by(trainsentences, list(train$id), lexicon="afinn")
pos.sent.t<-sentiment_by(testsentenses, list(test$id), lexicon="afinn")

train<-cbind(train,pos.sent[,4], swear.sent[,4], hate.sent[,4])
test<-cbind(test,pos.sent.t[,4], swear.sent.t[,4], hate.sent.t[,4])

rm(hatewords, key.hatewords, swears, id, stopWords, mykey.swear)

#Jack's work
traintest = rbind(train[,1:2], test[,1:2])
traintest = mutate(traintest,
       length = stri_length(comment_text),
       ncap = stri_count_charclass(comment_text, "[A-Z]"),
       nnum = stri_count_charclass(comment_text, "[0-9]"),
       ncap_len = ncap / length,
       nnum_len = nnum / length,
       nexcl = stri_count_fixed(comment_text, "!"),
       nquest = stri_count_fixed(comment_text, "?"),
       npunct = stri_count_charclass(comment_text, "[[:punct:]]"),
       npunct_len = npunct / length,
       nsent = stri_count_boundaries(comment_text, "sentence"),
       nsymb = stri_count_regex(comment_text, "&|@|#|\\$|%|\\*|\\^"),
       nsmile = stri_count_regex(comment_text, "((?::|;|=)(?:-)?(?:\\)|D|P))"),
       nwords = stri_count_words(comment_text),
       hate=stri_count_fixed(comment_text,c("nigger","fag")),
       nhate=stri_count_regex(comment_text, "[[hatewords$x]]")
       )
train = cbind(train, traintest[idtrain,3:ncol(traintest)])
test = cbind(test, traintest[idtest,3:ncol(traintest)])

## quanteda
ttcorp = corpus(traintest$comment_text)
ttdfm = dfm(ttcorp, remove = stopwords("english"))
ttdfm = dfm_trim(ttdfm, min_docfreq = 150, max_docfreq = 100000)
ttdfm = dfm_sort(ttdfm)

# sparse matrix
sumttdfm = summary(ttdfm)
sparsettdfm = sparseMatrix(i = sumttdfm$i, j = sumttdfm$j, x = sumttdfm$x)

sparsetrain = Matrix(as.matrix(train[3:ncol(train)]), sparse = TRUE)
sparsetest = Matrix(as.matrix(test[3:ncol(test)]), sparse = TRUE)
train = cbind(sparsetrain, sparsettdfm[1:nrow(train),])
test = cbind(sparsetest, sparsettdfm[(nrow(train)+1):(nrow(train) + nrow(test)),])
rm(sparsetrain, sparsetest, traintest, ttcorp, ttdfm, idtest, idtrain, sumttdfm, sparsettdfm)
```

### cv.glmnet

```{r}
toxicglm = cv.glmnet(train[,7:dim(train)[2]], 
                     factor(train[,1]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
toxicpreds = predict(toxicglm, newx = test[,1:dim(test)[2]], type = "response", s = "lambda.min")

severe_toxicglm = cv.glmnet(train[,7:dim(train)[2]], 
                     factor(train[,2]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
severe_toxicpreds = predict(severe_toxicglm, newx = test[,1:dim(test)[2]], type = "response", s = "lambda.min")

obsceneglm = cv.glmnet(train[,7:dim(train)[2]], 
                     factor(train[,3]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
obscenepreds = predict(obsceneglm, newx = test[,1:dim(test)[2]], type = "response", s = "lambda.min")

threatglm = cv.glmnet(train[,7:dim(train)[2]], 
                     factor(train[,4]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
threatpreds = predict(threatglm, newx = test[,1:dim(test)[2]], type = "response", s = "lambda.min")

insultglm = cv.glmnet(train[,7:dim(train)[2]], 
                     factor(train[,5]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
insultpreds = predict(insultglm, newx = test[,1:dim(test)[2]], type = "response", s = "lambda.min")

identity_hateglm = cv.glmnet(train[,7:dim(train)[2]], 
                     factor(train[,6]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
identity_hatepreds = predict(identity_hateglm, newx = test[,1:dim(test)[2]], type = "response", s = "lambda.min")

submission = cbind(testid, toxicpreds, severe_toxicpreds, obscenepreds, threatpreds, insultpreds, identity_hatepreds)
colnames(submission) = c("id", "toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate")
options(scipen = 100000)
write_csv(as.data.frame(submission), "submission.csv")
```

