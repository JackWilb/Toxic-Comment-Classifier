Natural Language Processing In R: A Wikipedia Case Study
========================================================
author: Jack Wilburn and Rob Squire
font-family: Georgia
date: 20th April 2018
autosize: true

```{r setup, include=FALSE}
opts_chunk$set(cache=TRUE)
```

Motivation
========================================================

* Text Analysis
* Develop Techniques
  - Data Aggregation/Cleaning
  - Modeling
  - Reporting

Objectives
========================================================

* Natural Language Processing (NLP)
  - Body Of Text
  - Useful Variables
  
* Predictive Modeling
  - Explantory Variables
  - 6 Response Variables
  - Inference
  
Methods 
========================================================

* Explore Raw Data

* Clean Data

* Create Variables

* Split data
  - Training/Test
  
Methods 
========================================================  

* Implement models 
  - Cross Validated Logistic Regression

* Assess Accuracy
  - Confusion Matrix

Libraries
========================================================

```{r, include = FALSE}
set.seed(1)
library(readr)
library(stringi)
library(quanteda)
library(dplyr)
library(caret)
library(glmnet)
library(doParallel)
registerDoParallel(4)
library(tidytext)
library(data.table)
library(sentimentr)
```

* readr
* stringi
* quanteda
* dplyr
* caret

***

* glmnet
* doParallel
* tidytext
* data.table
* sentimentr

Exploratory Data Analysis
========================================================

```{r,include=FALSE}
library(tidyverse)
train = read_csv("train.csv")
```

* Structure Of The Data
```{r, echo=FALSE}
head(as.data.frame(train[100,]), 1)
```

Exploratory Data Analysis
========================================================

```{r, include=FALSE}
table(train$toxic)
table(train$obscene)
table(train$threat)
table(train$insult)
table(train$identity_hate)
```

* Toxic: `r (15294/159571)*100` %.

* Severe_toxic: `r (1595/159571)*100 ` %.

* Obscene: `r (8449/159571)*100 ` %.

* Threat: `r (478/159571)*100 ` %.

* Insult: `r (7877/159571)*100 ` %.

* Identity Hate: `r (1405/159571)*100 ` %.

Tidy Text Word Analysis
========================================================

```{r, warning=FALSE, include=FALSE}
traincorpus = corpus(train$comment_text)
docvars(traincorpus, "id") = 1:nrow(train)
docvars(traincorpus, "toxic") = train$toxic
docvars(traincorpus, "severe_toxic") = train$severe_toxic
docvars(traincorpus, "obscene") = train$obscene
docvars(traincorpus, "threat") = train$threat
docvars(traincorpus, "insult") = train$insult
docvars(traincorpus, "identity_hate") = train$identity_hate
docvars(traincorpus, "ntokens") = ntoken(traincorpus, remove_punct = TRUE)

traindfm2 = dfm(traincorpus, remove = stopwords("english"), stem = TRUE, remove_punct = TRUE)
toxicdfm2 = dfm_subset(traindfm2, toxic == 1, remove = stopwords("english"))
toxicfeatures2 = topfeatures(toxicdfm2, 10)
toxicwords2 = names(toxicfeatures2)

severe_toxicdfm2 = dfm_subset(traindfm2, severe_toxic == 1,remove = stopwords("english"))
severe_toxicfeatures2 = topfeatures(severe_toxicdfm2, 10)
severe_toxicwords2 = names(severe_toxicfeatures2)

obscenedfm2 = dfm_subset(traindfm2, obscene == 1,remove = stopwords("english"))
obscenefeatures2 = topfeatures(obscenedfm2, 10)
obscenewords2 = names(obscenefeatures2)

threatdfm2 = dfm_subset(traindfm2, threat == 1,remove = stopwords("english"))
threatfeatures2 = topfeatures(threatdfm2, 10)
threatwords2 = names(threatfeatures2)

insultdfm2 = dfm_subset(traindfm2, insult == 1,remove = stopwords("english"))
insultfeatures2 = topfeatures(insultdfm2, 10)
insultwords2 = names(insultfeatures2)

identity_hatedfm2 = dfm_subset(traindfm2, identity_hate == 1,remove = stopwords("english"))
identity_hatefeatures2 = topfeatures(identity_hatedfm2, 10)
identity_hatewords2 = names(identity_hatefeatures2)
```

```{r, include = FALSE}
a = data.frame(term = c("f**k","ni**er","a*s","sex","hate","go","c*nt","like","suck","moron"), freq = unname(toxicfeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) +
    geom_bar(stat = 'identity', fill = 'orangered2') + theme(text=element_text(size=16))+
    labs(x = '', y = 'Frequency', title = 'Toxic') + 
    theme(axis.text.y = element_text(size = 40), plot.title = element_text(size = 50)) + 
    coord_flip()

b = data.frame(term = c("f**k","a*s","suck","u","go","bastard","c*nt","athiest","fire","pro.assad(...)"), freq = unname(severe_toxicfeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) +
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    theme(axis.text.y = element_text(size = 40), plot.title = element_text(size = 50)) +
    labs(x = '', y = 'Frequency', title = 'Severe_toxic') + 
    coord_flip() 

c = data.frame(term = c("f**k","ni**er","a*s","c*nt","suck","go","u","bollock","d*ckhead","like"), freq = unname(obscenefeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    theme(axis.text.y = element_text(size = 40), plot.title = element_text(size = 50)) +
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    labs(x = '', y = 'Frequency', title = 'Obscene') + 
    coord_flip() 

d = data.frame(term = c("a*s","will","supertr0l","die","live","pathet(ic)","forev(er)","fool","respect","f**k"), freq = unname(threatfeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    geom_bar(stat = 'identity', fill = 'orangered2') +
    theme(axis.text.y = element_text(size = 40), plot.title = element_text(size = 50)) + 
    labs(x = '', y = 'Frequency', title = 'Threat') + 
    coord_flip() 

e = data.frame(term = c("f**k","ni**er","a*s","hate","c*nt","go","moron","hi","u","suck"), freq = unname(insultfeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    theme(axis.text.y = element_text(size = 40), plot.title = element_text(size = 50)) +
    labs(x = '', y = 'Frequency', title = 'Insult') + 
    coord_flip() 


f = data.frame(term = c("ni**er","c*nt","tommy2010","licker","fan-1967","like","romney","mitt","homo","f**k"), freq = unname(identity_hatefeatures2)) %>%
    ggplot(aes(x = reorder(term, freq), y = freq)) + 
    theme(axis.text.y = element_text(size = 40), plot.title = element_text(size = 50)) +
    geom_bar(stat = 'identity', fill = 'orangered2') + 
    labs(x = '', y = 'Frequency', title = "Identity_hate") + 
    coord_flip() 
```

```{r, echo = FALSE, fig.width = 18, fig.height = 10}
gridExtra::grid.arrange(a,b, ncol = 2)
```

Tidy Text Word Analysis
========================================================

```{r, echo = FALSE, fig.width = 18, fig.height = 10}
gridExtra::grid.arrange(c,d, ncol = 2)
```

Tidy Text Word Analysis
========================================================

```{r, echo = FALSE, fig.width = 18, fig.height = 10}
gridExtra::grid.arrange(e,f, ncol = 2)
```


Word frequencies for associated classifications.  



PCA
========================================================

```{r, echo=FALSE, fig.width=18, fig.height=10}
train_num<-select_if(train, is.numeric)
train_num<-na.omit(train_num)
train_pca<- prcomp(train_num, scale=TRUE)
biplot(train_pca, xlabs=rep("",159571))
```

It behaves as we'd expect.


Variables Created
========================================================

* Feature Count 
  - Punctuation
  - Capital letters
  - Smileys
  
* Sentiment analysis
  - Standard Lexicon/ library - AFINN
  - Custom lexicon
    -Swear
    -Hate
  
Variables Created
========================================================  
    
* Sparse Document Feature Matrix
  - Counts of every possible "feature"
    - Words, punt, multiple words
    - 4000 features.
   


Results
========================================================

```{r, include = FALSE}
# Set seed for consistent results
set.seed(1)

# Importing Libraries
library(readr) # Importing and exporting csv files
library(stringi) # Fast string manipulation package (improved version of stringr)
library(quanteda) # Fast tokenizing and dfm creation (see methods)
library(dplyr) # Tidy variable creator and data cleaner
library(caret) # Predictive modeling package, used for confusionMatrix function (see methods) 
library(glmnet) # Predictive modeling package, used for cross validated logistic regression
library(doParallel) # Parallelizing model and dfm building
registerDoParallel(4) # Number of cores to be parallel over
library(tidytext) # Tidy data wrangling, used for stopwords
library(data.table) # Importing swear databases that are friendly with sentimentr
library(sentimentr) # Apply custom sentiments to words of interest

# Import dataset from Kaggle.com
train = read_csv("train.csv")

# Making the number of rows even, dropping the first observation
train = train[2:159571,]

# Splitting the dataset into a training and a testing set
sample = sample(nrow(train), nrow(train)/2)
test = train[-sample,]
train = train[sample,]
idtrain = 1:nrow(train)
idtest = (nrow(train)+1):(nrow(train) + nrow(test))
traintest = rbind(train[,1:2], test[1:2])
gc()

# Using dplyr and stringi to generate new variables related to properties of the strings
traintest = rbind(train[,1:2], test[1:2])
traintest = mutate(traintest,
       length = stri_length(comment_text),
       ncap = stri_count_charclass(comment_text, "[A-Z]"),
       nnum = stri_count_charclass(comment_text, "[0-9]"),
       ncap_len = ncap / length,
       nnum_len = nnum / length,
       nexcl = stri_count_fixed(comment_text, "!"),
       nquest = stri_count_fixed(comment_text, "?"),
       npunct = stri_count_charclass(comment_text, "[[:punct:]]"),
       npunct_len = npunct / length,
       nsent = stri_count_boundaries(comment_text, "sentence"),
       nsymb = stri_count_regex(comment_text, "&|@|#|\\$|%|\\*|\\^"),
       nsmile = stri_count_regex(comment_text, "((?::|;|=)(?:-)?(?:\\)|D|P))"),
       nwords = stri_count_words(comment_text)
       )
train = cbind(train, traintest[idtrain,3:ncol(traintest)])
test = cbind(test, traintest[idtest,3:ncol(traintest)])

###swears
swears<-fread("swears.csv", sep = ",")
hatewords<-fread("hatebase_dict1.csv",sep=",")
#swears2 <-fread("swearlistcscmu.csv",sep=",")
#swears3<-fread("googleswear.csv",sep=",")


swears<-unique( swears[ , 1:2 ] )
swears$x <- gsub(",","",swears$x)
#swears<-rbind(swears,swears2)
#swears<-rbind(swears,swears3)
swears<-unique(swears[,1:2])
mykey.swear<-update_key(swears)


hatewords<-unique(hatewords[,1:2])
hatewords$words<-gsub(",","",hatewords$words)
hatewords$words<-gsub("'"," ",hatewords$words)

hatewords$words<-tolower(hatewords$words)
hatewords
colnames(hatewords)[1] <- "x"
colnames(hatewords)[2]<-"y"
hatewords<-unique(hatewords[,1:2])
key.hatewords <- update_key(hatewords)

stopWords = c(stop_words$word, "of", "or", "on")
stopWords=stopWords[!(stopWords %in% c("new","used","small","large","thanks","greetings","works"))]

cmmnt = train$comment_text
cmmnt = unlist(cmmnt)[!(unlist(cmmnt) %in% stopWords)]
cmmnt = stri_replace_all_charclass(cmmnt, "[^[:alnum:]]", " ")
id = rep(1:nrow(train))
cmmnt_df = data.frame(id = id, comments = cmmnt)
cmmnt_df$comments = as.character(cmmnt_df$comments)


cmmnt.t = test$comment_text
cmmnt.t = unlist(cmmnt.t)[!(unlist(cmmnt.t) %in% stopWords)]
cmmnt.t = stri_replace_all_charclass(cmmnt.t, "[^[:alnum:]]", " ")
id = rep(1:nrow(test))
cmmnt_df.t = data.frame(id = id, comments = cmmnt.t)
cmmnt_df.t$comments = as.character(cmmnt_df.t$comments)


swear.sent.train<-sentiment_by(cmmnt_df$comments,list(id), polarity_dt=mykey.swear)
swear.sent.test<-sentiment_by(cmmnt_df.t$comments,list(id),polarity_dt=mykey.swear)

colnames(swear.sent.test)[4] <- "swear_sent"
colnames(swear.sent.train)[4]<-"swear_sent"


#cmmnt_df$comments<-na.omit(cmmnt_df$comments)
#cmmnt_df.t$comments<-na.omit(cmmnt_df.t$comments)

#hate.sent.train<-sentiment_by(cmmnt_df$comments,list(id), polarity_dt=key.hatewords)
#hate.sent.test<-sentiment_by(cmmnt_df.t$comments,list(id),polarity_dt=key.hatewords)

#colnames(hate.sent.test)[4] <- "hate_sent"
#colnames(hate.sent.train)[4]<-"hate_sent"

train<-cbind(train,swear.sent.train[,4])
test<-cbind(test,swear.sent.test[,4])
#train<-cbind(train,hate.sent.train[,4])
#test<-cbind(test,hate.sent.test[,4])
###positive sent- afinn
pos.sent<-sentiment_by(cmmnt_df$comments, list(id), lexicon="afinn")
pos.sent.t<-sentiment_by(cmmnt_df$comments, list(id), lexicon="afinn")

colnames(pos.sent)[4] <- "afinn"
colnames(pos.sent.t)[4]<-"afinn"

train<-cbind(train,pos.sent[,4])
test<-cbind(test,pos.sent.t[,4])


## quanteda
ttcorp = corpus(traintest$comment_text)
ttdfm = dfm(ttcorp, remove = stopwords("english"))
ttdfm = dfm_trim(ttdfm, min_docfreq = 150, max_docfreq = 100000)
ttdfm = dfm_sort(ttdfm)

# sparse matrix
sumttdfm = summary(ttdfm)
sparsettdfm = sparseMatrix(i = sumttdfm$i, j = sumttdfm$j, x = sumttdfm$x)

sparsetrain = Matrix(as.matrix(train[3:23]), sparse = TRUE)
sparsetest = Matrix(as.matrix(test[3:23]), sparse = TRUE)
train = cbind(sparsetrain, sparsettdfm[1:nrow(train),])
test = cbind(sparsetest, sparsettdfm[(nrow(train)+1):(nrow(train) + nrow(test)),])
rm(sparsetrain, sparsetest)

toxicglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,1]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 40,
                     standardize = T,
                     nlambda = 50)
toxicpreds = predict(toxicglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
toxicpreds = ifelse(toxicpreds > 0.27, 1 ,0)
toxicconf = confusionMatrix(factor(toxicpreds), factor(test[,1]))

severe_toxicglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,2]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
severe_toxicpreds = predict(severe_toxicglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
severe_toxicpreds = ifelse(severe_toxicpreds > 0.02, 1 ,0)
severe_toxicconf = confusionMatrix(factor(severe_toxicpreds), factor(test[,2]))

obsceneglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,3]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
obscenepreds = predict(obsceneglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
obscenepreds = ifelse(obscenepreds > 0.22, 1 ,0)
obsceneconf = confusionMatrix(factor(obscenepreds), factor(test[,3]))

threatglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,4]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
threatpreds = predict(threatglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
threatpreds = ifelse(threatpreds > 1, 1 ,0)
threatconf = confusionMatrix(factor(threatpreds), factor(test[,4]))

insultglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,5]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
insultpreds = predict(insultglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
insultpreds = ifelse(insultpreds > 0.21, 1 ,0)
insultconf = confusionMatrix(factor(insultpreds), factor(test[,5]))

identity_hateglm = cv.glmnet(train[,8:dim(train)[2]], 
                     factor(train[,6]), 
                     alpha = 0, 
                     family = "binomial", 
                     type.measure = "auc",
                     parallel = T,
                     nfolds = 4,
                     standardize = T,
                     nlambda = 50)
identity_hatepreds = predict(identity_hateglm, newx = test[,8:dim(test)[2]], type = "response", s = "lambda.min")
identity_hatepreds = ifelse(identity_hatepreds > 1, 1 ,0)
identity_hateconf = confusionMatrix(factor(identity_hatepreds), factor(test[,6]))
```


* Toxic = `r toxicconf$overall[1]`. 
  - `r unname((toxicconf$overall[1]-toxicconf$overall[5])/(1-toxicconf$overall[5]))*100` % increase
  
* Severe_Toxic = `r severe_toxicconf$overall[1]`
  - `r unname((severe_toxicconf$overall[1]-severe_toxicconf$overall[5])/(1-severe_toxicconf$overall[5]))*100` % increase
  
* Obscene = `r obsceneconf$overall[1]`
  - `r unname((obsceneconf$overall[1]-obsceneconf$overall[5])/(1-obsceneconf$overall[5]))*100` % increase

Results
========================================================  

* Threat = `r threatconf$overall[1]`
  - `r unname((threatconf$overall[1]-threatconf$overall[5])/(1-threatconf$overall[5]))*100` % increase
  
* Insult = `r insultconf$overall[1]`
  - `r unname((insultconf$overall[1]-insultconf$overall[5])/(1-insultconf$overall[5]))*100` % increase
  
* Identity_Hate = `r identity_hateconf$overall[1]`
  - `r unname((identity_hateconf$overall[1]-identity_hateconf$overall[5])/(1-identity_hateconf$overall[5]))*100` % increase

Discussion
========================================================

* Satistically signficant Classifications:
  - Toxic
  - Obscene
  - Insult
  
* No Improvement:
  - Severe_toxic
  - Threat
  - Identity_hate
  
Discussion
========================================================
  
* Significant Variables:
  - Sentiment Analysis
  - Document Feature Matrix


Limitations
========================================================

* Data Size:

  - Prevalence (0.3% Threat)
  
  - Machine Learning Limited

* Computing power:
  
  - N-grams
  
  - Feature Combinations
  
  - Unkown Variables


Acknowledgements
========================================================

http://www.bannedwordlist.com/lists/swearWords.txt

https://www.cs.cmu.edu/~biglou/resources/bad-words.txt

https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/lexicons

https://www.tidytextmining.com/tidytext.html

https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge



